{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Processing for CHIR Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/6y/z0315m514rx79r25lwyjx_d80000gn/T/ipykernel_1962/1237687372.py\", line 2, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/arrow/array.py\", line 50, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/ops/__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/ops/array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/computation/expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/computation/check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/numexpr/__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/6y/z0315m514rx79r25lwyjx_d80000gn/T/ipykernel_1962/1237687372.py\", line 2, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/arrow/array.py\", line 64, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py\", line 60, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/bottleneck/__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "# set-up steps\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import time\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# data loading\n",
    "\n",
    "CHIR_df = pd.read_csv(\"CHIR_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHIR Processed Data successfully exported to: derived_data/CHIR_processed_for_Airtable.csv\n"
     ]
    }
   ],
   "source": [
    "# setting up a data check for potential duplicates\n",
    "\n",
    "# Typology for duplicates (pending confirmation)\n",
    "dupe_code_list = {\"cross_state_duplicate\", \"document_type_duplicate\", \"non_duplicate\", \"payer_duplicate\",\"true_duplicate\"}\n",
    "\n",
    "# Converting the policy identifier column to a more useful format (numeric to string)\n",
    "CHIR_df['Policy Identifier'] = CHIR_df['Policy Identifier'].astype(str)\n",
    "\n",
    "# Creating a duplicate flagger function for this data stream\n",
    "# This flags duplicates in the DataFrame based on Policy Identifier, States, Document Type, and Payer.\n",
    "\n",
    "def flag_duplicates(CHIR_df):\n",
    "\n",
    "    # Sort the DataFrame to ensure consistent grouping for duplicates\n",
    "    CHIR_df_sorted = CHIR_df.sort_values(by=[\"Policy Identifier\", \"States\", \"Document Type\", \"Payer\"])\n",
    "\n",
    "    # Initialize the 'duplicate_flagger' column with a default value\n",
    "    CHIR_df_sorted[\"duplicate_flagger\"] = \"non_duplicate\"\n",
    "\n",
    "    # Identify where there are the same 'Policy Identifier' but different 'States'.\n",
    "    cross_state_dupes = CHIR_df_sorted.groupby(\"Policy Identifier\").filter(\n",
    "        lambda x: x[\"States\"].nunique() > 1\n",
    "    )\n",
    "    CHIR_df_sorted.loc[cross_state_dupes.index, \"duplicate_flagger\"] = \"cross_state_duplicate\"\n",
    "    \n",
    "\n",
    "    # Identify where there are the same 'Policy Identifier' and 'States' but different 'Document Type'.\n",
    "    doc_type_dupes_mask = (\n",
    "        (CHIR_df_sorted.duplicated(subset=[\"Policy Identifier\", \"States\"], keep=False))\n",
    "        & (\n",
    "            ~CHIR_df_sorted.duplicated(\n",
    "                subset=[\"Policy Identifier\", \"States\", \"Document Type\"], keep=False\n",
    "            )\n",
    "        )\n",
    "        & (CHIR_df_sorted[\"duplicate_flagger\"] == \"non_duplicate\")\n",
    "    )\n",
    "    CHIR_df_sorted.loc[doc_type_dupes_mask, \"duplicate_flagger\"] = \"document_type_duplicate\"\n",
    "    \n",
    "\n",
    "\n",
    "    # Identify where there are the same 'Policy Identifier' and 'States' but different 'Payer'.\n",
    "    payer_dupes_mask = (\n",
    "        (CHIR_df_sorted.duplicated(subset=[\"Policy Identifier\", \"States\"], keep=False))\n",
    "        & (\n",
    "            ~CHIR_df_sorted.duplicated(\n",
    "                subset=[\"Policy Identifier\", \"States\", \"Payer\"], keep=False\n",
    "            )\n",
    "        )\n",
    "        & (CHIR_df_sorted[\"duplicate_flagger\"] == \"non_duplicate\")\n",
    "    )\n",
    "    CHIR_df_sorted.loc[payer_dupes_mask, \"duplicate_flagger\"] = \"payer_duplicate\"\n",
    "    \n",
    "\n",
    "    # Identifying true duplicates, where all these factors are identical\n",
    "    true_dupes_mask = (\n",
    "        CHIR_df_sorted.duplicated(\n",
    "            subset=[\"Policy Identifier\", \"States\", \"Document Type\", \"Payer\"], keep=False\n",
    "        )\n",
    "        & (CHIR_df_sorted[\"duplicate_flagger\"] == \"non_duplicate\")\n",
    "    )\n",
    "    CHIR_df_sorted.loc[true_dupes_mask, \"duplicate_flagger\"] = \"true_duplicate\"\n",
    "    \n",
    "\n",
    "    return CHIR_df_sorted\n",
    "\n",
    "# Running the function on the CHIR data\n",
    "dupecheck_CHIR_df = flag_duplicates(CHIR_df.copy())\n",
    "\n",
    "# Exporting the modified version\n",
    "output_path = \"derived_data/CHIR_processed_for_Airtable.csv\"\n",
    "dupecheck_CHIR_df.to_csv(output_path, index= False)\n",
    "\n",
    "print(f\"CHIR Processed Data successfully exported to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHIR Categorized CGM Data successfully exported to: derived_data/cat_CHIR_processed_for_Airtable.csv\n"
     ]
    }
   ],
   "source": [
    "# CGM grouping exercise\n",
    "# This categorizes CGM product coverage based on if they are 'Dexcom' and 'FreeStyle'\n",
    "\n",
    "\n",
    "def categorize_cgm_coverage(df: pd.DataFrame, column_name: str) -> pd.DataFrame:\n",
    "\n",
    "    # Create an empty list to store the labels for the new column\n",
    "    cgm_grouping_labels = []\n",
    "\n",
    "    # Iterate through each cell in the specified column\n",
    "    for cell_value in df[column_name]:\n",
    "        # Initialize flags for Dexcom and FreeStyle presence\n",
    "        has_dexcom = False\n",
    "        has_freestyle = False\n",
    "\n",
    "        # Handle missing or empty values first\n",
    "        if pd.isna(cell_value) or str(cell_value).strip() == '':\n",
    "            cgm_grouping_labels.append(\"No coverage\")\n",
    "            continue # Move to the next cell\n",
    "\n",
    "        # Convert the cell value to a string and then to lowercase for case-insensitive matching\n",
    "        # Split the string by commas to get individual product names\n",
    "        products = str(cell_value).lower().split(',')\n",
    "\n",
    "        # Check for the presence of 'dexcom' and 'freestyle' in any of the product names\n",
    "        for product in products:\n",
    "            if \"dexcom\" in product:\n",
    "                has_dexcom = True\n",
    "            if \"freestyle\" in product:\n",
    "                has_freestyle = True\n",
    "\n",
    "        # Apply the labeling logic based on the flags\n",
    "        if has_dexcom and has_freestyle:\n",
    "            cgm_grouping_labels.append(\"both Dexcom and FreeStyle\")\n",
    "        elif has_dexcom:\n",
    "            cgm_grouping_labels.append(\"Dexcom only\")\n",
    "        elif has_freestyle:\n",
    "            cgm_grouping_labels.append(\"FreeStyle only\")\n",
    "        else:\n",
    "            # If neither Dexcom nor FreeStyle are found, but the cell was not empty,\n",
    "            # it means other products are covered.\n",
    "            cgm_grouping_labels.append(\"Others covered\")\n",
    "\n",
    "    # Assign the generated labels to the new 'CGM_grouping' column in the DataFrame\n",
    "    df['CGM_grouping'] = cgm_grouping_labels\n",
    "\n",
    "    return df\n",
    "\n",
    "# test run\n",
    "cat_CHIR_df = categorize_cgm_coverage(dupecheck_CHIR_df.copy(), 'CGMs Covered')\n",
    "\n",
    "# Exporting the modified version\n",
    "output_path = \"derived_data/cat_CHIR_processed_for_Airtable.csv\"\n",
    "cat_CHIR_df.to_csv(output_path, index= False)\n",
    "\n",
    "print(f\"CHIR Categorized CGM Data successfully exported to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHIR Implanted/non-implanted & counted CGM Data successfully exported to: derived_data/counted_and_implanted_CHIR_processed_for_Airtable.csv\n"
     ]
    }
   ],
   "source": [
    "# grouping for implanted\n",
    "\n",
    "# writing a dictionary based on the table\n",
    "device_implant_dict = {\n",
    "    \"Eversense E3 rtCGM\": \"implanted\",\n",
    "    \"Eversense 365\": \"implanted\",\n",
    "    \"Medtronic Guardian 3 rtCGM\": \"non-implanted\",\n",
    "    \"Medtronic Guardian 4 rtCGM\": \"non-implanted\",\n",
    "    \"Medtronic Simplera rtCGM\": \"non-implanted\",\n",
    "    \"Medtronic Simplera Sync rtCGM\": \"non-implanted\",\n",
    "    \"Dexcom G6 rtCGM\": \"non-implanted\",\n",
    "    \"Dexcom G7 rtCGM\": \"non-implanted\",\n",
    "    \"Abbott FreeStyle Libre 2 Plus rtCGM\": \"non-implanted\",\n",
    "    \"Abbott FreeStyle Libre 3 Plus rtCGM\": \"non-implanted\",\n",
    "    \"Abbott FreeStyle Libre 2 isCGM\": \"non-implanted\",\n",
    "    \"Abbott FreeStyle Libre 14 isCGM\": \"non-implanted\",\n",
    "    \"Unspecified - transcutaneous rtCGM\": \"non-implanted\",\n",
    "    \"Unspecified - transcutaneous isCGM\": \"non-implanted\",\n",
    "    \"Unspecified - implantable rtCGM\": \"implanted\",\n",
    "    \"Unspecified\": \"unknown\"\n",
    "}\n",
    "\n",
    "# iterating through our data (with a copy for safety)\n",
    "implanted_CHIR_df = cat_CHIR_df.dropna(subset=['CHIR Review Fields Last Modified']).copy()\n",
    "\n",
    "# building an iterating function to run through the data\n",
    "def categorize_implanted_type(df: pd.DataFrame, column_name: str) -> pd.DataFrame:\n",
    "\n",
    "    # create an empty list to store the labels for the new column\n",
    "    implanted_type_labels = []\n",
    "\n",
    "    # iterate through each cell in the specified column\n",
    "    for cell_value in df[column_name]:\n",
    "        # handling missing or empty values\n",
    "        if pd.isna(cell_value) or str(cell_value).strip() == '':\n",
    "            implanted_type_labels.append(\"no devices\")\n",
    "            continue\n",
    "\n",
    "        # separating multi-device coverage by commas\n",
    "        products_in_cell = str(cell_value).split(',')\n",
    "        \n",
    "        has_implanted_device = False\n",
    "        has_non_implanted_device = False\n",
    "        \n",
    "        # check in case any unknowns (or spelling variations)\n",
    "        found_any_known_device_in_cell = False \n",
    "\n",
    "        # check each product in the cell against the dictionary\n",
    "        for product_in_cell in products_in_cell:\n",
    "            for mapped_device_name, status in device_implant_dict.items():\n",
    "                # check for partial matches: if the mapped name is in the product string, or vice-versa\n",
    "                if mapped_device_name in product_in_cell or product_in_cell in mapped_device_name:\n",
    "                    found_any_known_device_in_cell = True\n",
    "                    if status == \"implanted\":\n",
    "                        has_implanted_device = True\n",
    "                    elif status == \"non-implanted\":\n",
    "                        has_non_implanted_device = True\n",
    "                    break\n",
    "\n",
    "        # applying the labeling logic based on the flags after checking all products in the cell\n",
    "        if has_implanted_device and has_non_implanted_device:\n",
    "            implanted_type_labels.append(\"both implanted and non-implanted\")\n",
    "        elif has_implanted_device:\n",
    "            implanted_type_labels.append(\"implanted only\")\n",
    "        elif has_non_implanted_device:\n",
    "            implanted_type_labels.append(\"non-implanted only\")\n",
    "        else:\n",
    "            implanted_type_labels.append(\"unknown device type\") \n",
    "\n",
    "    # assign the generated labels to the new 'Implanted_Type' column\n",
    "    df['Implanted_Type'] = implanted_type_labels\n",
    "\n",
    "    return df\n",
    "\n",
    "# test run with our copied data\n",
    "implanted_CHIR_df = categorize_implanted_type(implanted_CHIR_df, 'CGMs Covered')\n",
    "\n",
    "# supplementing the data to include a count of the number of devices\n",
    "def count_cell_items(df: pd.DataFrame, column_name: str, new_column_name: str) -> pd.DataFrame:\n",
    "    totals = []\n",
    "    for cell_value in df[column_name]:\n",
    "        if pd.isna(cell_value) or str(cell_value).strip() == '':\n",
    "            totals.append(0) # 0 for empty cells\n",
    "        else:\n",
    "            items = [item.strip() for item in str(cell_value).split(',') if item.strip()]\n",
    "            totals.append(len(items))\n",
    "    \n",
    "    df[new_column_name] = totals\n",
    "    return df    \n",
    "\n",
    "implanted_CHIR_df = count_cell_items(implanted_CHIR_df, 'CGMs Covered', 'CGM_count')\n",
    "\n",
    "# exporting the modified version\n",
    "new_output_path = \"derived_data/counted_and_implanted_CHIR_processed_for_Airtable.csv\"\n",
    "implanted_CHIR_df.to_csv(new_output_path, index= False)\n",
    "\n",
    "print(f\"CHIR Implanted/non-implanted & counted CGM Data successfully exported to: {new_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webscraping and data organization -- pulling the CHIR documents\n",
    "\n",
    "# adding packages\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
